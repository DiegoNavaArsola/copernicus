}
if (df1[[j+1,3]]==9) {
prueba[j+1,1] <- df1[[j+1,i]]
taux2 <- table(cont_mul_var(prueba,","))
for (t2_length in 1:(dim(taux2)-2)) {
Ncx1[t2_length+1,i] <- taux2[[t2_length+1]]
}
}
}
else{
Nx1[j,i] <- sum(df1[[i]] == j-1,na.rm = T)
Ncx1[j,i] <- sum(df1[[i]] == j-1 & (df1[[3]] == 7 | df1[[3]] == 9),na.rm = T)
}
}
}
taux2
View(Nx1)
View(Nx1)
taux1
df1 <- data_cop_simp
for (z in 1:dim(df1)[1]) {
if (is.na(df1$Correo[z]) == TRUE) {
df1$Correo[z] <- 0
}
else{
df1$Correo[z] <- 1
}
if (is.na(df1$Facebook[k]) == TRUE) {
df1$Facebook[z] <- 0
}
else{
df1$Facebook[z] <- 1
}
}
Nx1 = matrix(NA, nrow = dim(df)[1]+1, ncol = dim(df)[2])
Ncx1 = matrix(NA, nrow = dim(df)[1]+1, ncol = dim(df)[2])
epsilon1 = matrix(NA, nrow = dim(df)[1]+1, ncol = dim(df)[2])
prueba <- matrix(0,nrow = dim(df)[1]+2,ncol = 1)
for (i in 1:dim(df1)[2]) {
for (j in 0:236) {
#    if (i == 10) {
if (is.character(df1[[i]]) == TRUE) {
aux1 <- cont_mul_var(df1[[i]],",")
taux1 <- table(aux1)
for (t1_length in 1:(dim(taux1)-2)) {
Nx1[t1_length+1,i] <- taux1[[t1_length+1]]
}
if (df1[[j+1,3]]==9) {
prueba[j+1,1] <- df1[[j+1,i]]
taux2 <- table(cont_mul_var(prueba,","))
for (t2_length in 1:(dim(taux2)-2)) {
Ncx1[t2_length+1,i] <- taux2[[t2_length+1]]
}
}
}
else{
Nx1[j,i] <- sum(df1[[i]] == j-1,na.rm = T)
Ncx1[j,i] <- sum(df1[[i]] == j-1 & (df1[[3]] == 7 | df1[[3]] == 9),na.rm = T)
}
}
}
df1 <- data_cop_simp
for (z in 1:dim(df1)[1]) {
if (is.na(df1$Correo[z]) == TRUE) {
df1$Correo[z] <- 0
}
else{
df1$Correo[z] <- 1
}
if (is.na(df1$Facebook[k]) == TRUE) {
df1$Facebook[z] <- 0
}
else{
df1$Facebook[z] <- 1
}
}
Nx1 = matrix(NA, nrow = dim(df)[1]+1, ncol = dim(df)[2])
Ncx1 = matrix(NA, nrow = dim(df)[1]+1, ncol = dim(df)[2])
epsilon1 = matrix(NA, nrow = dim(df)[1]+1, ncol = dim(df)[2])
prueba <- matrix(0,nrow = dim(df)[1]+2,ncol = 1)
for (i in 1:dim(df1)[2]) {
for (j in 0:236) {
#    if (i == 10) {
if (is.character(df1[[i]]) == TRUE) {
aux1 <- cont_mul_var(df1[[i]],",")
taux1 <- table(aux1)
for (t1_length in 1:(dim(taux1)-2)) {
Nx1[t1_length+1,i] <- taux1[[t1_length+1]]
}
if (df1[[j+1,3]]==7 | df1[[j+1,3]]==9) {
prueba[j+1,1] <- df1[[j+1,i]]
taux2 <- table(cont_mul_var(prueba,","))
for (t2_length in 1:(dim(taux2)-2)) {
Ncx1[t2_length+1,i] <- taux2[[t2_length+1]]
}
}
}
else{
Nx1[j,i] <- sum(df1[[i]] == j-1,na.rm = T)
Ncx1[j,i] <- sum(df1[[i]] == j-1 & (df1[[3]] == 7 | df1[[3]] == 9),na.rm = T)
}
}
}
sum(df$Status==7 | df$Status=9)
sum(df$Status==7 | df$Status==9)
#Tamaño de la base de datos
n <- dim(df)[1]
#Clases a tratar / na.rm = T sirve para ignorar NAN
Nc <- sum(df$Status == 7 | df$Status == 9,na.rm = T)
#Data frame con los datos del agua
#df <- Copernicus_Data_set
df <- data_cop_simp
#Tamaño de la base de datos
n <- dim(df)[1]
#Clases a tratar / na.rm = T sirve para ignorar NAN
Nc <- sum(df$Status == 7 | df$Status == 9,na.rm = T)
#Vector con el nombre de las variables
nomvar <- names(df)
#Funcion para contar variables con celdas con multiples datos (sep es un string)
cont_mul_var <- function(column,sep) {
column.string <- paste(column,collapse = sep)
column.vector <- strsplit(column.string, sep)
return(column.vector)
}
create_temp_df <- function(matrix) {
}
#Funcion para contar variables con celdas con multiples datos (sep es un string)
cont_mul_var <- function(column,sep) {
column.string <- paste(column,collapse = sep)
column.vector <- strsplit(column.string, sep)
return(column.vector)
}
x <- c(0:128)
y <- c(213,215,431,596)
nclas <- c(x,y)
lnc <- length(nclas)
#Inicialización de matrices
Nx = matrix(0, nrow = dim(df)[1]+1, ncol = dim(df)[2])
Ncx = matrix(0, nrow = dim(df)[1]+1, ncol = dim(df)[2])
epsilon = matrix(0, nrow = dim(df)[1]+1, ncol = dim(df)[2])
arg_ln = matrix(0, nrow = dim(df)[1]+1, ncol = dim(df)[2])
score = matrix(0, nrow = dim(df)[1]+1, ncol = dim(df)[2])
temp <- matrix(0,nrow = dim(df)[1]+1,ncol = 1)
for (k in 1:dim(df)[1]) {
if (is.na(df$Correo[k]) == TRUE) {
df$Correo[k] <- 0
}
else{
df$Correo[k] <- 1
}
if (is.na(df$Facebook[k]) == TRUE) {
df$Facebook[k] <- 0
}
else{
df$Facebook[k] <- 1
}
}
for (i in 1:dim(df)[2]) {
for (j in 0:dim(df)[1]-2) {
if (is.character(df[[i]]) == TRUE) {
aux <- cont_mul_var(df[[i]],",")
taux <- table(aux)
for (t_length in 1:(dim(taux)-2)) {
Nx[t_length+1,i] <- taux[[t_length+1]]
}
if (df[[j+1,3]]==7 | df[[j+1,3]]==9) {
prueba[j+1,1] <- df[[j+1,i]]
taux2 <- table(cont_mul_var(prueba,","))
for (t2_length in 1:(dim(taux2)-2)) {
Ncx[t2_length+1,i] <- taux2[[t2_length+1]]
}
}
}
else{
Nx[j,i] <- sum(df[[i]] == j-1,na.rm = T)
Ncx[j,i] <- sum(df[[i]] == j-1 & (df[[3]] == 7 | df[[3]] == 9),na.rm = T)
}
epsilon[j,i] <- (Nx[j,i]*((Ncx[j,i]/Nx[j,i])-(Nc/n)))/(Nx[j,i]*(Nc/n)*sqrt((1-(Nc/n))))
arg_ln[j,i] <- (Ncx[j,i]/Nc)/((Nx[j,i]-Ncx[j,i])/(n-Nc))
score[j,i] <- log(arg_ln[j,i],exp(1))
}
}
dim(df)[1]
for (i in 1:dim(df)[2]) {
for (j in 0:(dim(df)[1]-1)) {
if (is.character(df[[i]]) == TRUE) {
aux <- cont_mul_var(df[[i]],",")
taux <- table(aux)
for (t_length in 1:(dim(taux)-2)) {
Nx[t_length+1,i] <- taux[[t_length+1]]
}
if (df[[j+1,3]]==7 | df[[j+1,3]]==9) {
prueba[j+1,1] <- df[[j+1,i]]
taux2 <- table(cont_mul_var(prueba,","))
for (t2_length in 1:(dim(taux2)-2)) {
Ncx[t2_length+1,i] <- taux2[[t2_length+1]]
}
}
}
else{
Nx[j,i] <- sum(df[[i]] == j-1,na.rm = T)
Ncx[j,i] <- sum(df[[i]] == j-1 & (df[[3]] == 7 | df[[3]] == 9),na.rm = T)
}
epsilon[j,i] <- (Nx[j,i]*((Ncx[j,i]/Nx[j,i])-(Nc/n)))/(Nx[j,i]*(Nc/n)*sqrt((1-(Nc/n))))
arg_ln[j,i] <- (Ncx[j,i]/Nc)/((Nx[j,i]-Ncx[j,i])/(n-Nc))
score[j,i] <- log(arg_ln[j,i],exp(1))
}
}
for (i in 1:dim(df)[2]) {
for (j in 0:(dim(df)[1]-1)) {
if (is.character(df[[i]]) == TRUE) {
aux <- cont_mul_var(df[[i]],",")
taux <- table(aux)
for (t_length in 1:(dim(taux)-2)) {
Nx[t_length+1,i] <- taux[[t_length+1]]
}
Nx[is.nan(Nx)] <- 0
if (df[[j+1,3]]==7 | df[[j+1,3]]==9) {
prueba[j+1,1] <- df[[j+1,i]]
taux2 <- table(cont_mul_var(prueba,","))
for (t2_length in 1:(dim(taux2)-2)) {
Ncx[t2_length+1,i] <- taux2[[t2_length+1]]
}
Ncx[is.nan(Ncx)] <- 0
}
}
else{
Nx[j,i] <- sum(df[[i]] == j-1,na.rm = T)
Ncx[j,i] <- sum(df[[i]] == j-1 & (df[[3]] == 7 | df[[3]] == 9),na.rm = T)
}
epsilon[j,i] <- (Nx[j,i]*((Ncx[j,i]/Nx[j,i])-(Nc/n)))/(Nx[j,i]*(Nc/n)*sqrt((1-(Nc/n))))
arg_ln[j,i] <- (Ncx[j,i]/Nc)/((Nx[j,i]-Ncx[j,i])/(n-Nc))
score[j,i] <- log(arg_ln[j,i],exp(1))
}
}
warning()
warnings()
View(Ncx)
View(Ncx)
epsilon
#Convierte NaN en ceros
epsilon[is.nan(epsilon)] <- 0
score[is.nan(score)] <- 0
#Covierte infinitos en ceros
score[is.infinite(score)] <- 0
View(data_cop_simp)
View(data_cop_simp)
nomvar[19]
#Data frame con los datos del agua
#df <- Copernicus_Data_set
df <- data_cop_simp
#Tamaño de la base de datos
n <- dim(df)[1]
#Clases a tratar / na.rm = T sirve para ignorar NAN
Nc <- sum(df$Status == 7 | df$Status == 9,na.rm = T)
#Vector con el nombre de las variables
nomvar <- names(df)
#Funcion para contar variables con celdas con multiples datos (sep es un string)
cont_mul_var <- function(column,sep) {
column.string <- paste(column,collapse = sep)
column.vector <- strsplit(column.string, sep)
return(column.vector)
}
x <- c(0:128)
y <- c(213,215,431,596)
nclas <- c(x,y)
lnc <- length(nclas)
#Inicialización de matrices
Nx = matrix(0, nrow = dim(df)[1]+1, ncol = dim(df)[2])
Ncx = matrix(0, nrow = dim(df)[1]+1, ncol = dim(df)[2])
epsilon = matrix(0, nrow = dim(df)[1]+1, ncol = dim(df)[2])
arg_ln = matrix(0, nrow = dim(df)[1]+1, ncol = dim(df)[2])
score = matrix(0, nrow = dim(df)[1]+1, ncol = dim(df)[2])
temp <- matrix(0,nrow = dim(df)[1]+1,ncol = 1)
for (k in 1:dim(df)[1]) {
if (is.na(df$Correo[k]) == TRUE) {
df$Correo[k] <- 0
}
else{
df$Correo[k] <- 1
}
if (is.na(df$Facebook[k]) == TRUE) {
df$Facebook[k] <- 0
}
else{
df$Facebook[k] <- 1
}
}
for (i in 1:dim(df)[2]) {
for (j in 0:(dim(df)[1]-1)) {
if (is.character(df[[i]]) == TRUE) {
aux <- cont_mul_var(df[[i]],",")
taux <- table(aux)
for (t_length in 1:(dim(taux)-2)) {
Nx[t_length+1,i] <- taux[[t_length+1]]
}
Nx[is.nan(Nx)] <- 0
if (df[[j+1,3]]==7 | df[[j+1,3]]==9) {
prueba[j+1,1] <- df[[j+1,i]]
taux2 <- table(cont_mul_var(prueba,","))
for (t2_length in 1:(dim(taux2)-2)) {
Ncx[t2_length+1,i] <- taux2[[t2_length+1]]
}
Ncx[is.nan(Ncx)] <- 0
}
}
else{
Nx[j,i] <- sum(df[[i]] == j-1,na.rm = T)
Ncx[j,i] <- sum(df[[i]] == j-1 & (df[[3]] == 7 | df[[3]] == 9),na.rm = T)
}
epsilon[j,i] <- (Nx[j,i]*((Ncx[j,i]/Nx[j,i])-(Nc/n)))/(Nx[j,i]*(Nc/n)*sqrt((1-(Nc/n))))
arg_ln[j,i] <- (Ncx[j,i]/Nc)/((Nx[j,i]-Ncx[j,i])/(n-Nc))
score[j,i] <- log(arg_ln[j,i],exp(1))
}
}
#Data frame con los datos del agua
#df <- Copernicus_Data_set
df <- data_cop_simp
#Tamaño de la base de datos
n <- dim(df)[1]
#Clases a tratar / na.rm = T sirve para ignorar NAN
Nc <- sum(df$Status == 7 | df$Status == 9,na.rm = T)
#Vector con el nombre de las variables
nomvar <- names(df)
#Funcion para contar variables con celdas con multiples datos (sep es un string)
cont_mul_var <- function(column,sep) {
column.string <- paste(column,collapse = sep)
column.vector <- strsplit(column.string, sep)
return(column.vector)
}
#Inicialización de matrices
Nx = matrix(0, nrow = dim(df)[1]+1, ncol = dim(df)[2])
#Inicialización de matrices
Nx = matrix(NA, nrow = dim(df)[1]+1, ncol = dim(df)[2])
Ncx = matrix(NA, nrow = dim(df)[1]+1, ncol = dim(df)[2])
epsilon = matrix(NA, nrow = dim(df)[1]+1, ncol = dim(df)[2])
arg_ln = matrix(NA, nrow = dim(df)[1]+1, ncol = dim(df)[2])
score = matrix(NA, nrow = dim(df)[1]+1, ncol = dim(df)[2])
temp <- matrix(NA,nrow = dim(df)[1]+1,ncol = 1)
for (k in 1:dim(df)[1]) {
if (is.na(df$Correo[k]) == TRUE) {
df$Correo[k] <- 0
}
else{
df$Correo[k] <- 1
}
if (is.na(df$Facebook[k]) == TRUE) {
df$Facebook[k] <- 0
}
else{
df$Facebook[k] <- 1
}
}
for (i in 1:dim(df)[2]) {
for (j in 0:(dim(df)[1]-1)) {
if (is.character(df[[i]]) == TRUE) {
aux <- cont_mul_var(df[[i]],",")
taux <- table(aux)
for (t_length in 1:(dim(taux)-2)) {
Nx[t_length+1,i] <- taux[[t_length+1]]
}
if (df[[j+1,3]]==7 | df[[j+1,3]]==9) {
prueba[j+1,1] <- df[[j+1,i]]
taux2 <- table(cont_mul_var(prueba,","))
for (t2_length in 1:(dim(taux2)-2)) {
Ncx[t2_length+1,i] <- taux2[[t2_length+1]]
}
}
}
else{
Nx[j,i] <- sum(df[[i]] == j-1,na.rm = T)
Ncx[j,i] <- sum(df[[i]] == j-1 & (df[[3]] == 7 | df[[3]] == 9),na.rm = T)
}
Nx[is.nan(Nx)] <- 0
Ncx[is.nan(Ncx)] <- 0
epsilon[j,i] <- (Nx[j,i]*((Ncx[j,i]/Nx[j,i])-(Nc/n)))/(Nx[j,i]*(Nc/n)*sqrt((1-(Nc/n))))
arg_ln[j,i] <- (Ncx[j,i]/Nc)/((Nx[j,i]-Ncx[j,i])/(n-Nc))
score[j,i] <- log(arg_ln[j,i],exp(1))
}
}
nomvar[11]
install.packages("dataPreparation")
install.packages("RTools")
install.packages("dataPreparation")
.libPaths()
install.packages("dataPreparation")
install.Rtools()
install.packages(rtools)
install.packages("rtools")
dft <- df
train_index <- sample(1:nrow(df),0.8*nrow(df))
test_index <- setdiff(1:nrow(df),train_index)
install.packages("dataPreparation")
install.packages(c("tibble", "tinytex"))
install.packages("dataPreparation")
library(dataPreparation)
X_train <- dft[train_index, -15]
dft[train_index]
dft[train_index,1]
train_index
y_train <- dft[train_index, "Promedio"]
X_test <- dft[test_index, -15]
y_test <- dft[test_index, "Promedio"]
#Filtrado de variables
constant_cols <- whichAreConstant(dft)
double_cols <- whichAreInDouble(dft)
bijections_cols <- whichAreBijection(dft)
#Calificacion x/100 es biyección de Calificacionx/128 -> Remover
X_train$`Calificación x/100` <- NULL
X_test$`Calificación x/100` <- NULL
##
# Escalado y normalización
##
scales <- build_scales(dataSet = X_train, cols = c("Calificación x/128","Promedio"), verbose = TRUE)
print(scales)
X_train <- fastScale(dataSet = X_train,scales = scales, verbose = TRUE)
X_test <- fastScale(dataSet = X_test, scales = scales, verbose = TRUE)
print(head(X_train[, c("Calificación x/128","Promedio")]))
##
# Discretizacion
##
#bins <- build_bins(dataSet = X)
X_train <- fastDiscretization(dataSet = X_train, bins = list(promedio = c(0,5,6,7,8,9,10,+Inf)))
##
# Discretizacion
##
#bins <- build_bins(dataSet = X)
X_train <- fastDiscretization(dataSet = X_train, bins = list(Promedio = c(0,5,6,7,8,9,10,+Inf)))
print(table(X_train$Promedio))
##
# Discretizacion
##
#bins <- build_bins(dataSet = X)
X_train <- fastDiscretization(dataSet = X_train, bins = list("Calificación x/128" = c(0, 30, 60, 70, 80, 90, 100, 105, 110, +Inf)))
print(table(X_train$`Calificación x/128`))
##
# Discretizacion
##
#bins <- build_bins(dataSet = X)
X_train <- fastDiscretization(dataSet = X_train, bins = list("Calificación x/128" = c(0, 30, 60, +Inf)))
##
# Discretizacion
##
#bins <- build_bins(dataSet = X)
X_train <- fastDiscretization(dataSet = X_train, bins = list("Calificación x/128" = c(0, 30, 60, +Inf)))
dft <- df
##
# Dividir la base de datos en 80% train y 20% test
##
train_index <- sample(1:nrow(df),0.8*nrow(df))
test_index <- setdiff(1:nrow(df),train_index)
X_train <- dft[train_index, -15]
y_train <- dft[train_index, "Promedio"]
X_test <- dft[test_index, -15]
y_test <- dft[test_index, "Promedio"]
###
# Filtrado de variables
###
constant_cols <- whichAreConstant(dft)
double_cols <- whichAreInDouble(dft)
bijections_cols <- whichAreBijection(dft)
#Calificacion x/100 es biyección de Calificacionx/128 -> Remover
X_train$`Calificación x/100` <- NULL
X_test$`Calificación x/100` <- NULL
##
# Escalado y normalización
##
scales <- build_scales(dataSet = X_train, cols = c("Calificación x/128","Promedio"), verbose = TRUE)
X_train <- fastScale(dataSet = X_train,scales = scales, verbose = TRUE)
X_test <- fastScale(dataSet = X_test, scales = scales, verbose = TRUE)
##
# Discretizacion
##
#bins <- build_bins(dataSet = X)
X_train <- fastDiscretization(dataSet = X_train, bins = list("Calificación x/128" = c(0, 30, 60, +Inf)))
print(table(X_train$`Calificación x/128`))
##
# Discretizacion
##
#bins <- build_bins(dataSet = X)
X_train <- fastDiscretization(dataSet = X_train, bins = list("Calificación x/128" = c(0, 30, 60, 70, 80, 90, 100, 105, 110, +Inf)))
dft <- df
##
# Dividir la base de datos en 80% train y 20% test
##
train_index <- sample(1:nrow(df),0.8*nrow(df))
test_index <- setdiff(1:nrow(df),train_index)
X_train <- dft[train_index, -15]
y_train <- dft[train_index, "Promedio"]
X_test <- dft[test_index, -15]
y_test <- dft[test_index, "Promedio"]
###
# Filtrado de variables
###
constant_cols <- whichAreConstant(dft)
double_cols <- whichAreInDouble(dft)
bijections_cols <- whichAreBijection(dft)
#Calificacion x/100 es biyección de Calificacionx/128 -> Remover
X_train$`Calificación x/100` <- NULL
X_test$`Calificación x/100` <- NULL
##
# Escalado y normalización
##
scales <- build_scales(dataSet = X_train, cols = c("Calificación x/128","Promedio"), verbose = TRUE)
X_train <- fastScale(dataSet = X_train,scales = scales, verbose = TRUE)
X_test <- fastScale(dataSet = X_test, scales = scales, verbose = TRUE)
##
# Discretizacion
##
#bins <- build_bins(dataSet = X)
X_train <- fastDiscretization(dataSet = X_train, bins = list("Calificación x/128" = c(0, 30, 60, 70, 80, 90, 100, 105, 110, +Inf)))
print(table(X_train$`Calificación x/128`))
